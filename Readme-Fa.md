<style>*{direction: rtl}</style>
# تسک فنی

مجموعه داده booksummaries.txt به ما داده شده است و هدف آن ایجاد یک اسکریپت یا نوت بوک پایتون است که NLP، Computer Vision، Machine Learning و Data Visualization را برای تجزیه و تحلیل و درک مجموعه داده ای از خلاصه کتاب ها ترکیب می کند. این شامل پاکسازی داده ها، بررسی ویژگی های آن از طریق EDA، کوتاه کردن خلاصه ها و تبدیل آنها به تصاویر است که در زیر به تفصیل توضیح می دهیم. و ما می خواهیم با انجام این مراحل "خلاصه های متن فشرده"، "تصاویر تبدیل شده" و "یافته های حاصل از تجزیه و تحلیل داده های اکتشافی (EDA)" را بدست آوریم.

## پیش پردازش داده و تحلیل داده های اکتشافی (EDA)

### بارگذاری و پیش پردازش داده

- بارگذاری داده با استفاده کتابخانه pandas و افزودن هدر به آن.
- بررسی قسمتی از داده و دیدن شکل آن.
- حذف ستون‌های `Wikipedia article ID` و `Freebase ID` از داده ها.
- اضافه کردن ایندکس به دیتاست.
- تمیز کردن ژانر کتاب ها و تغییر ساختار آن به لیستی از ژانر.
- اضافه کردن ستون `Publication year` از روی ستون `Publication date` که فقط حاوی سال انتشار کتاب است.
- مشخص کردن ردیف‌های تکراری و حذف آن از طریق ستون های `Book title` و `Author`
- تمیز کردن ستون `Plot summary` با استفاده از کوچک کردن حروف، حذف علائم نگارشی، حذف اعداد، حذف فاصله های اضافی، حذف کاراکترهای خاص، حذف کلمات ربط(stopwords)، پاک کردن فاصله های اضافی ابتدا و انتهای متن و در نهایت بررسی میشود که آیا متن تمیز شده خالی است یا خیر و در صورت خالی بودن مقدار `NaN` و در صورت خالی نبودن `متن تمیز شده` به عنوان محتوای جدید در ستون `Cleaned Summary` ثبت میشود.
- حذف رکوردهایی که ستون `Cleaned Summary` آن مقدار ندارد.
- حذف داده های پرت با استفاده روش IQR
- پر کردن داده های گمشده `Author` با مقدار `Unknown` چون نمی توانیم کتاب شخص دیگری را به نام شخص دیگری ثبت کنیم
- پر کردن داده های گمشده `Book genres` با توجه به `Author` و ژانر دیگر کتاب های این نویسنده که موجود است و پیدا کردن 5 ژانر مرسوم کتاب های این نویسنده
- محاسبه میانه، مد و میانگین `Publication year` و رسم نمودار هیستوگرام آن  که از طریق آن متوجه شویم کدام یک از این موارد برای داده های گمشده `Publication Year` و `Publication date` مناسب است.

<div style="text-align:center;">
    <img src='./assets/publication_year_hist.png'></img>
</div>

- از طریق نمودار هیستوگرام به علت تداخل و زیاد بودن داده‌ها نمیتوان متوجه چیزی شد پس نمودار هیستوگرام را برای 10 سال برتر(Top 10) رسم میکنیم و متوجه میشویم که تمامی این 10 سال متعلق به 2000 به بعد است و به همین دلیل از مد به عنوان مقداری برای پر کردن داده های گمشده `Publication Year` و `Publication date` استفاده میکنیم.

<div style="text-align:center;">
    <img src='./assets/top10_publication_year_hist.png'></img>
</div>

- برای دیگر داده های گمشده `Book genres` مقدار `Unknown` را قرار می دهیم.
- بررسی میکنیم که داده های گمشده برای هیچ کدام از ستون ها موجود نباشد.
- در نهایت داده های تمیز شده را با فرمت csv ذخیره می کنیم.


برای مدیریت داده های گمشده روش های متعددی وجود دارد که یکی از آن ها را برای ستون `Book genres` به کار بردیم و آن نیز تشخیص ژانر کتاب ها بر اساس دیگر آثار نویسنده بوده است و پیدا کردن 5 ژانر مرسوم از این دیگر آثار بوده است ولی روش های دیگری نیز وجود دارد که می توانیم از آن استفاده کنیم که ما فقط سه مورد از آن را که برای این مسئله کاربرد دارد نام میبریم. اولین روش استفاده که نمی توانیم از آن استفاده کنیم روش `Forwardfill/Backwardfill` است که اگر داده های دارای توالی منطقی باشند می توانیم با استفاده از این روش داده های گمشده را پر کنیم. روش دیگر استفاده از منابع خارجی برای یافتن داده است مثل استفاده از دیتاست خارجی، استفاده از APIs(مثل Google Books API, GoodReads or Freebase) و یا با استفاده از نوشتن یک خزنده وب و پیدا کردن اطلاعات مورد نظر(ظاهرا مقادیر ستون `Wikipedia article ID` معتبر نیست). روش سوم نیز استفاده از یک مدل NLP از قبل آموزش دیده که بتواند به طور خاص ژانر کتاب‌ها را با توجه به نیاز ما تشخیص دهد.


### درک و کاوش کردن ویژگی های مجموعه داده از طریق EDA

برای کاوش کردن مجموعه داده و آنالیز کردن ویژگی های آن از آنالیز عددی برای داده های عددی و از آنالیز غیر عددی برای ویژگی های غیر عددی مثل ژانر کتاب ها صورت گرفته که به ترتیب آن‌ها را در زیر شرح میدهیم.

- خواندن مجموعه داده ذخیره شده از مرحله قبل که در فایل csv ذخیره شده است.
- تبدیل ژانر کتاب ها به لیستی از ژانرها برای آنالیز غیرعددی
- چاپ کردن اطلاعات پایه مجموعه داده مثل تعداد کتاب‌ها و داده های گمشده


```sh
Number of books: 15593
Missing values: False
```

- تحلیل عددی روی `Summary Length` یعنی طول خلاصه کتاب‌ها و نمایش داده های با نمودار جعبه ای

```sh
Summary length statistics:
count    15593.000000
mean       184.366575
std        155.291544
min          1.000000
25%         63.000000
50%        130.000000
75%        268.000000
max        668.000000
```

<div style="text-align:center;">
    <img src='./assets/summary_length_box_plot.png'></img>
</div>


- تحلیل عددی روی `Publication year` یعنی سال انتشار کتاب‌ها و نمایش داده های با نمودار جعبه ای

```sh
Publication year statistics:
count    15593.000000
mean      1986.779581
std         42.171144
min        398.000000
25%       1982.000000
50%       2004.000000
75%       2007.000000
max       2013.000000
```

<div style="text-align:center;">
    <img src='./assets/publication_year_box_plot.png'></img>
</div>

- تحلیل توزیع `Book genres` یعنی ژانر کتاب‌ها و نمایش 10 ژانر برتر با نمودار میله‌ای. لازم به ذکر است که در این حالت هر کتاب دارای چندین ژانر بوده است و این تعداد تکرارهای هر ژانر را نمایش میدهد.

```sh
Genre distribution:
Fiction                4401
Speculative fiction    3995
Unknown                3552
Science Fiction        2675
Novel                  2312
                       ... 
Popular culture           1
Neuroscience              1
Alien invasion            1
Comedy of manners         1
Pastiche                  1
Length: 223
```

<div style="text-align:center;">
    <img src='./assets/top10_most_distrubution_of_book_genres.png'></img>
</div>


- تحلیل توزیع `Publication year` یعنی  سال انتشار کتاب‌ها و نمایش 20 سال انتشار برتر با نمودار میله‌ای. لازم به ذکر است که سال 2007 به عنوان، مد مجموعه داده انتخاب شده و این اختلاف ناشی از اینکه داده های گمشده را با آن پر کرده ایم نیز میشود.

```sh
Publication year distribution:

Publication year
2007.0    5756
2006.0     422
2008.0     366
2005.0     362
2004.0     338
          ... 
1590.0       1
1768.0       1
1621.0       1
1516.0       1
1640.0       1
Length: 264
```

<div style="text-align:center;">
    <img src='./assets/top20_distribution_of_publication_year.png'></img>
</div>


- تحلیل محبوبیت نویسندگان یعنی `Author` و نمایش 20 نویسنده برتر با نمودار میله‌ای. البته در نمایش این تحلیل مقدار `Unknown` که برای داده های گمشده این ستون به کار برده شده بود حذف شده است و در نمودار نمایش داده نمیشود.

```sh
Author analysis:

Author
Unknown                 2294
Franklin W. Dixon         67
K. A. Applegate           60
Agatha Christie           58
Edgar Rice Burroughs      57
                        ... 
Mary Cheney                1
Nick Enright               1
Sion Sono                  1
Ntozake Shange             1
Stephen Colbert            1
Length: 4553
```

<div style="text-align:center;">
    <img src='./assets/author_popularity.png'></img>
</div>

- تحلیل رخداد همزمانی ژانر کتاب‌ها که یعنی چه ژانرهایی بیشترین بار با هم رخ داده‌اند و نمایش نمودار میله‌ای 10 رخداد برتر آن


```sh
(Science Fiction, Speculative fiction)    1860
(Speculative fiction, Fiction)            1829
(Speculative fiction, Fantasy)            1186
(Children's literature, Fiction)          1037
(Science Fiction, Fiction)                1001
(Fantasy, Fiction)                         941
(Mystery, Fiction)                         802
(Fiction, Novel)                           745
(Fiction, Suspense)                        620
(Mystery, Suspense)                        613
```

<div style="text-align:center;">
    <img src='./assets/genre_co-occurrence.png'></img>
</div>


## کامپوننت پردازش زبان طبیعی

در این بخش تسک خواسته شده از ما این بوده است که خلاصه کتاب‌های موجود در دیتاست را به خلاصه کوتاه‌تری تبدیل کنیم که ما نیز با استفاده مدل `facebook/bart-large-cnn` که نام عمومی آن BART است و از بین سه مدل BART و T5 و PEGASUS ما این مدل را انتخاب کردیم چون برای خلاصه های با کیفیت بالا و با فشرده سازی متوسط عالی بود بنابراین مدل را آماده کردیم که در صورت وجود GPU بتواند از آن استفاده کند و در صورت نبود آن از CPU. ‌دو تابع به نام‌های `summarize_batch` و `batch_summarization` تعریف کردیم که تابع اول کار گرفتن دسته‌ای از متن ها و خلاصه کردن آن با استفاده از مدل BART را به عهده دارد و تابع دوم کار مدیریت کردن داده‌های دیتاست و فرستادن آن به صورت دسته دسته را به عهده دارد که به مشکل کمبود حافظه رم(Memory error) برنخوریم. بعد از آن یک متن را به عنوان نمونه به مدل دادیم و دقت و طول متن خلاصه شده را سنجیدیم که در زیر نتایج آن آورده شده است و همانطور که مشخص است طول متن قبل از خلاصه شدن 531 توکن یا به عبارتی میتوان گفت کلمه بوده است و بعد از استفاده از مدل BART و خلاصه کردن متن به 72 کلمه کاهش پیدا کرده است.

```sh
Cleaned Summary lenght: 531
Summarized Text lenght: 72
```
نتایج دقت مدل روی خلاصه کردن این متن نیز به صورت زیر است که با استفاده از کتابخانه `rouge_score` نتایج بدست آمده است.

```sh
ROUGE-1:  Score(precision=1.0, recall=0.13559322033898305, fmeasure=0.23880597014925373)
ROUGE-2:  Score(precision=1.0, recall=0.1339622641509434, fmeasure=0.2362728785357737)
ROUGE-L:  Score(precision=1.0, recall=0.13559322033898305, fmeasure=0.23880597014925373)
```

امتیازات ROUGE به دست آمده، به ما بینش ارزشمندی از عملکرد مدل خلاصه‌سازی شما ارائه می‌دهند. در زیر تجزیه‌وتحلیلی از این نتایج آورده شده است:

### **ROUGE-1:**
- **Precision = 1.0**: این نشان می‌دهد که 100٪ از unigrams (کلمات فرد) در خلاصه در متن اصلی وجود دارند. به عبارت دیگر، تمام کلمات خلاصه در متن اصلی حضور دارند.
- **Recall = 0.136**: تنها حدود 13.6٪ از unigrams متن اصلی در خلاصه شامل شده‌اند، به این معنی که خلاصه بسیار فشرده است.
- **F1-Score = 0.239**: این امتیاز نمایانگر میانگین هارمونیک بین precision و recall است که هر دو معیار را متعادل می‌کند. در حالی که precision کامل است، recall نسبتاً پایین، F1-score را پایین می‌کشاند.

### **ROUGE-2:**
- **Precision = 1.0**: تمام bigrams (جفت‌های کلمات متوالی) در خلاصه در متن اصلی ظاهر شده‌اند.
- **Recall = 0.134**: تنها حدود 13.4٪ از bigrams متن اصلی در خلاصه حاضر هستند که نشان می‌دهد پوشش bigram محتوای اصلی محدود است.
- **F1-Score = 0.236**: این امتیاز تعادل بین precision و recall برای bigrams را نشان می‌دهد. مشابه ROUGE-1، precision کامل توسط recall پایین تعدیل می‌شود.

### **ROUGE-L:**
- **Precision = 1.0**: تمامی زیردنباله‌های مشترک بلند (قطعات متنی که ترتیب کلمات را حفظ می‌کنند) در خلاصه در متن اصلی حاضر هستند.
- **Recall = 0.136**: حدود 13.6٪ از دنباله‌های متن اصلی در خلاصه شامل شده‌اند که دوباره نشان می‌دهد خلاصه بسیار فشرده است.
- **F1-Score = 0.239**: این امتیاز تعادل بین precision و recall برای زیردنباله‌ها را نشان می‌دهد، مشابه unigrams و bigrams.

### **تفسیر:**
- **Precision کامل (1.0)**: تمام کلمات، bigrams و دنباله‌ها در خلاصه مستقیماً از متن اصلی گرفته شده‌اند. این بدان معناست که خلاصه از نظر انتخاب و ترتیب کلمات بسیار وفادار به خلاصه اصلی است.
- **Recall پایین (حدود 13.5٪)**: خلاصه فقط شامل بخش کوچکی از متن اصلی است که نشان دهنده کاهش قابل توجهی در محتوا است. این به دلیل است که خلاصه به صورت اختصاصی کوتاه شده است.
- **F1-scores (حدود 0.239)**: امتیازهای F1 تعادل بین precision و recall را نشان می‌دهند. از آنجایی که precision کامل است اما recall پایین است، امتیازهای F1 نسبتاً پایین هستند.

### **خلاصه یافته‌ها:**
- مدل خلاصه‌سازی خلاصه‌هایی تولید می‌کند که **بسیار دقیق** هستند و اطمینان حاصل می‌شود که کلمات و عبارات استفاده شده به درستی از متن اصلی برداشته شده‌اند.
- با این حال، **recall پایین** نشان می دهد که خلاصه‌ها یک بخش بزرگی از محتوای اصلی را حذف کرده‌اند و این باعث شده است که آنها بسیار فشرده باشند.
- در صورتی که هدف ما تولید **خلاصه‌های کوتاه و مختصر** باشد، این سطح فشرده‌سازی ممکن است ایده‌آل باشد که هدف ما نیز همین است. از سوی دیگر، اگر بخواهیم محتوای بیشتری از محتوای اصلی را حفظ کنیم، ممکن است نیاز به **افزایش طول خلاصه** یا تنظیم پارامترهای مدل داشته باشیم.


در نهایت نیز نتایج این قسمت را به عنوان ستون `Summarized_Text` به دیتاست اضافه کرده و فایل دیتاست را به صورت csv ذخیره کرده‌ایم.


## کامپوننت بینایی ماشین

در این قسمت به عنوان تسک از ما خواسته شده که از خلاصه کتاب های تولید شده مرحله قبل با استفاده از مدل های متن به عکس، این متن ها را به عکس تبدیل کنیم. و برای این کار ما از ما از مدل `CompVis/stable-diffusion-v1-4` استفاده کردیم.(اگر این سوال را دارید که چرا از ورژن 1.5 استفاده نکردیم به این دلیل بود که در دسترس نبود علیرغم اینکه در [huggingface](https://huggingface.co/docs/diffusers/en/api/pipelines/stable_diffusion/text2img) از آن نام برده شده و داکیومنت آن موجود بود هنگام دریافت مدل خطای 404 میداد.)

برای این قسمت سه تابع `text_to_image` و `batch_text_to_images` و `display_image` نوشته شده است که به ترتیب تابع اول این وظیفه را دارد که متن ورودی را به عکس تبدیل کرده و آن را به ما تحویل دهد و در این قسمت متغیرهایی نیز تعریف شده که بتوانیم روی خروجی موردنظر کنترل بیشتری داشته باشیم از قبیل سایز طول و عرض عکس و همچنین تعداد عکس تولید شده برای متن ورودی. تابع دوم کار انجام فرستادن دسته دسته متن های دیتاست را به تابع اول انجام می‌دهد که حافظه رم  مدیریت شده و خطای حافظه(Memory Error) دریافت نکنیم و همچنین اینکه به دلیل محدودیت زمانی استفاده از GPU در گوگل کولب به خطا نخوریم و بتوانیم در مدت زمانی که به ما منابع را تحویل میدهد استفاده بهینه داشته باشیم. تابع سوم نیز عکسی را به عنوان ورودی گرفته و آن را نمایش میدهد و فقط جهت تست مدل که متنی برای آن فرستاده میشود تا به عنوان نمونه یک عکس تولید کند و نمایش دهد استفاده میشود.
